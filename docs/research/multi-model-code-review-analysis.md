# Multi-Model AI Code Review: 10 LLMs Analyze context-builder v0.7.0

> **Date**: February 14, 2026  
> **Project**: [context-builder](https://github.com/igorls/context-builder) v0.7.0  
> **Prompt**: Deep Think v2 â€” code review + relevance ordering evaluation  
> **Context file**: ~460KB, generated by context-builder itself (self-referential review)

## Abstract

We submitted context-builder v0.7.0's full source code to 10 AI models using a structured code review prompt. The context was generated by context-builder itself, creating a self-referential test: the tool's output quality directly affected the models' ability to review it. This exposed real bugs (e.g., lockfile starvation) that only manifested *because* the models consumed the tool's own output.

The models collectively identified **10 unique bugs**, achieved **universal consensus** on 4 architectural improvements, and proposed a clear roadmap for v2 output format. This document captures the full comparative analysis.

---

## 1. Methodology

### 1.1 Prompt Design

All models received the same structured prompt ("Deep Think v2") containing:
1. **Role**: Senior Rust developer and CLI tool architect
2. **Task**: Review context-builder v0.7.0 with focus on correctness, architecture, and a new relevance ordering feature
3. **Context**: The full output of `context-builder -d . --filter rs,toml,md` run against its own repository
4. **Specific asks**: Verify 5 bug fixes from v0.6.1â†’v0.7.0, evaluate relevance ordering, propose v2 output format

### 1.2 Model Access Methods

| Method | Models | Description |
|--------|--------|-------------|
| ðŸ§  **One-shot** | Gemini Deep Think, Gemini Pro, Grok 4.1, Qwen-3-Max, GLM-5 (Ã—2), ChatGPT 5.2, Kimi K2.5 | Single prompt + context file, no tool access |
| ðŸ¤– **Agentic** | Claude Opus 4.6, MiniMax Agent 2.5 | Multi-step sessions with file search, workspace tools, iterative reasoning |

> **Why this matters**: One-shot models that found deep bugs did so purely through reasoning over 460KB of context in a single pass. Agentic models could iteratively search, grep, and verify â€” giving them a structural advantage for precision but not necessarily for discovery depth.

### 1.3 Lockfile Fix (Mid-Experiment)

GLM-5's first run (pre-fix) was truncated because `Cargo.lock` (39KB) was classified as config (category 0), consuming the entire context window before source code appeared. We fixed this bug (moving lockfiles to category 4) and re-ran GLM-5, creating a natural A/B test of the fix's effectiveness.

Post-fix models (ChatGPT 5.2, Kimi K2.5, Claude Opus 4.6, MiniMax Agent, GLM-5 run 2) reviewed the corrected ordering.

---

## 2. Models Tested

| # | Model | Method | Context | Lockfile Fix | Quality |
|---|-------|--------|---------|-------------|---------|
| 1 | **Gemini 3 Deep Think** | ðŸ§  One-shot | Full | Pre-fix | ðŸŸ¢ Excellent |
| 2 | **Gemini 3 Pro** | ðŸ§  One-shot | Full | Pre-fix | ðŸŸ¢ Good |
| 3 | **Grok 4.1** | ðŸ§  One-shot | Full | Pre-fix | ðŸŸ¡ Average |
| 4 | **Qwen-3-Max** | ðŸ§  One-shot | Full | Pre-fix | ðŸŸ¢ Good |
| 5 | **GLM-5** (run 1, pre-fix) | ðŸ§  One-shot | Truncated | Pre-fix | ðŸ”´ Truncated |
| 6 | **GLM-5** (run 2, post-fix) | ðŸ§  One-shot | Partial | Post-fix | ðŸŸ¡ Partial |
| 7 | **ChatGPT 5.2** | ðŸ§  One-shot | Full | Post-fix | ðŸŸ¢ Excellent |
| 8 | **Kimi K2.5** | ðŸ§  One-shot | Full | Post-fix | ðŸŸ¢ Good |
| 9 | **Claude Opus 4.6** | ðŸ¤– Agentic | Full | Post-fix | ðŸŸ¢ Excellent |
| 10 | **MiniMax Agent 2.5** | ðŸ¤– Agentic | Full | Post-fix | ðŸŸ¢ Good |

> **Response files**: Each model's raw response is archived in [`docs/`](../):
> `context_v2_resp-gemini-3-deepthink.md`, `context_v2_resp-gemini-3-pro.md`, `context_v2_resp-grok-4.1.md`, `context_v2_resp-qwen-3-max.md`, `context_v2_resp-glm5.md`, `context_v2_resp-glm5-run2.md`, `context_v2_resp-chat-gpt-5.2.md`, `context_v2_resp-kimi-k2.5.md`, `context_v2_resp-claude-opus-4.6.md`, `context_v2_resp-minimax-agent.md`

---

## 3. Results: Model Rankings

### 3.1 Overall (Raw Output Quality)

| Rank | Model | Method | Unique Bugs | Novel Ideas | v0.6.1 Fix Verification |
|------|-------|--------|------------|-------------|------------------------|
| ðŸ¥‡ | **Claude Opus 4.6** | ðŸ¤– Agentic | 2 | Signatures-first format, `[category:N]` tags | 5/5 âœ… |
| ðŸ¥ˆ | **Gemini Deep Think** | ðŸ§  One-shot | 2 | XML CDATA format, BTreeMap ordering bug | 5/5 âœ… |
| ðŸ¥‰ | **ChatGPT 5.2** | ðŸ§  One-shot | 1 | Tests-before-source ordering | 5/5 âœ… |
| 4th | **Qwen-3-Max** | ðŸ§  One-shot | 1 | Progressive disclosure | 5/5 âœ… |
| 5th | **MiniMax Agent 2.5** | ðŸ¤– Agentic | 0 | XML w/ purpose summaries | 5/5 âœ… |
| 6th | **Kimi K2.5** | ðŸ§  One-shot | 0 | `--docs-first` flag, heat map | 5/5 âœ… |
| 7th | **Gemini Pro** | ðŸ§  One-shot | 0 | â€” | 5/5 âœ… |
| 8th | **GLM-5** (run 2) | ðŸ§  One-shot | 1 | Reliability column concept | 2/5 |
| 9th | **Grok 4.1** | ðŸ§  One-shot | 0 | â€” | 5/5 âœ… |
| 10th | **GLM-5** (run 1) | ðŸ§  One-shot | 1 (accidental) | â€” | 0/5 (truncated) |

### 3.2 Adjusted (Normalized for Methodology)

When accounting for the agentic advantage (tool access, iterative search, workspace), the efficiency picture changes:

| Rank | Model | Reasoning |
|------|-------|-----------|
| ðŸ¥‡ | **Gemini Deep Think** ðŸ§  | Found 2 unique *architectural* bugs (BTreeMap ordering, DefaultHasher non-determinism) in a single reasoning pass â€” no tools, no iteration. The auto-diff BTreeMap bug was the deepest finding across all 10 models, found by no other. |
| ðŸ¥ˆ | **ChatGPT 5.2** ðŸ§  | Most original thinker. Proposed tests-before-source ordering that no other model considered. One unique bug. Entirely one-shot. |
| ðŸ¥‰ | **Claude Opus 4.6** ðŸ¤– | Highest raw quality, but had agentic advantage. Line-level citations and signatures-first v2 format are best-in-class, but required multi-step tool-assisted processing. |
| 4th | **Qwen-3-Max** ðŸ§  | Strong one-shot. Caught parallel `max_tokens` and header token omission bugs independently. |
| 5th | **Kimi K2.5** ðŸ§  | Solid one-shot with practical, implementable suggestions (`--docs-first` flag). |

**Key insight**: Deep Think matched Claude Opus in bug *discovery depth* with zero tool access â€” pure one-shot reasoning over 460KB of context. This suggests extended reasoning traces are competitive with agentic tool-use for code review tasks. The agentic advantage primarily manifests in citation precision (exact line numbers), not bug discovery.

---

## 4. Bug Matrix

### 4.1 All Bugs Found (10 unique)

| # | Bug | Severity | DT | GP | GR | QW | G5 | G5Â² | GPT | K2 | CO | MM | Consensus |
|---|-----|----------|----|----|----|----|----|----|-----|----|----|----|----|
| 1 | `max_tokens` ignored in parallel mode | ðŸ”´ Critical | âœ… | | | âœ… | | | | âœ… | âœ… | | 4/10 |
| 2 | mtime hash â‰  content hash (breaks determinism) | ðŸ”´ Critical | âœ… | âœ… | | âœ… | | | âœ… | | âœ… | âœ… | 6/10 |
| 3 | `DefaultHasher` non-deterministic across Rust versions | ðŸŸ¡ High | âœ… | | | | | | âœ… | | âœ… | âœ… | 4/10 |
| 4 | Auto-diff `BTreeMap` destroys relevance ordering | ðŸ”´ Critical | âœ… | | | | | | | | | | 1/10 |
| 5 | Header/tree tokens not counted in budget | ðŸŸ¡ High | | | | âœ… | | | | | âœ… | | 2/10 |
| 6 | `contains("test")` substring false positives | ðŸŸ¡ Medium | | | | âœ… | | | | âœ… | âœ… | | 3/10 |
| 7 | `strip_prefix('+')` incomplete for diff indentation | ðŸŸ¢ Low | âœ… | | | | | | | | | | 1/10 |
| 8 | 4-byte/token estimate ~20% off for code | ðŸŸ¡ High | | | | | | | âœ… | âœ… | âœ… | âœ… | 4/10 |
| 9 | Binary file content stored as `String` in cache | ðŸŸ¢ Low | | | | | | âœ… | | | | | 1/10 |
| 10 | `starts_with("test_")` matches root-level helpers | ðŸŸ¡ Medium | | | | | | | | | âœ… | | 1/10 |

**Legend**: DT=Deep Think, GP=Gemini Pro, GR=Grok, QW=Qwen, G5=GLM-5 run 1, G5Â²=GLM-5 run 2, GPT=ChatGPT 5.2, K2=Kimi K2.5, CO=Claude Opus, MM=MiniMax

### 4.2 Bug Descriptions

**#1 â€” `max_tokens` ignored in parallel mode** (4/10): The `--max-tokens` flag is only enforced in the sequential code path. When parallel processing is used, files are concatenated without budget enforcement, potentially exceeding the token limit.

**#2 â€” mtime hash â‰  content hash** (6/10): The cache uses `file.modified()` timestamp for hashing. A `git checkout` or `cp` changes mtime without changing content â†’ different hash â†’ broken prompt caching across machines, CI environments, or even consecutive runs.

**#3 â€” `DefaultHasher` non-deterministic** (4/10): Rust's `std::hash::DefaultHasher` explicitly does not guarantee stable output across compiler versions or architectures. This silently breaks cache invalidation when the binary is compiled with different toolchains.

**#4 â€” Auto-diff BTreeMap destroys relevance** (1/10, Deep Think only): When `auto_diff = true` and full file content is rendered, the code iterates over `BTreeMap<PathBuf, FileState>` â€” which is alphabetically ordered by path, completely overriding the relevance-based sort from `file_utils.rs`. Since `auto_diff = true` is the recommended config, **relevance ordering doesn't work in the primary usage path**.

**#5 â€” Header/tree tokens not in budget** (2/10): The file tree header and section headers consume tokens but aren't deducted from `max_tokens`, meaning the actual file content budget is smaller than specified.

**#6 â€” Test substring false positives** (3/10): `rel_str.contains("test")` matches files like `latest_results.rs` or `contest_entry.rs`. Fixed during this experiment by switching to path boundary matching.

**#7 â€” `strip_prefix('+')` incomplete** (1/10, Deep Think only): Unified diff format uses `+ code` (plus, space, code). `strip_prefix('+')` removes the `+` but leaves the leading space, causing indentation mismatch.

**#8 â€” 4-byte/token estimate inaccurate** (4/10): The hardcoded 4 bytes/token ratio is an average across natural language. Code (which has more symbols, shorter identifiers) typically runs closer to 3.2 bytes/token, making estimates ~20% off.

**#9 â€” Binary content as String** (1/10, GLM-5 run 2 only): Binary file content passed through `String` type in the cache layer, potentially causing encoding issues or silent corruption.

**#10 â€” `starts_with("test_")` matches root helpers** (1/10, Claude Opus only): Root-level test helper files (e.g., `test_utils.rs`) in the project root would be classified as test files even if they're shared helpers used by production code.

---

## 5. Consensus: Relevance Ordering

### 5.1 Universal Agreement

All 10 models agreed on these points:
- âœ… Config-first ordering is correct (10/10)
- âœ… Lockfiles should be last or excluded (10/10)
- âœ… Entry points (`main.rs`, `lib.rs`) should be elevated within source (9/10)
- âœ… Alphabetical ordering within categories is suboptimal (9/10)

### 5.2 Where Should Docs Go?

| Position | Models | Count |
|----------|--------|-------|
| Core docs FIRST (README before source) | Deep Think, ChatGPT 5.2, GLM-5Â², Claude Opus | 4 |
| Docs after config, before source | Qwen, Kimi K2.5, MiniMax | 3 |
| Docs LAST (current behavior) | Grok, Gemini Pro | 2 |
| Configurable via flag | Kimi K2.5 (`--docs-first`) | 1 |

**Winner (7/10)**: Core docs (README, AGENTS.md) should appear before source code.

### 5.3 Proposed Category System

Based on consensus across all models:

```
0 â€” Core Docs      (README.md, AGENTS.md, ARCHITECTURE.md)
1 â€” Config/Manifest (Cargo.toml, package.json, pyproject.toml)
2 â€” Build/CI        (.github/, Dockerfile, build.rs, Makefile)
3 â€” Source          (src/*, entry points elevated)
4 â€” Tests/Benches   (tests/*, benches/*)
5 â€” Other Docs      (CHANGELOG, DEVELOPMENT, etc.)
6 â€” Generated/Lock  (Cargo.lock, package-lock.json â€” or excluded)
```

### 5.4 Intra-Category Ordering

| Approach | Models Proposing | Feasibility |
|----------|-----------------|-------------|
| Entry points first (`main.rs`, `lib.rs`) | DT, GPT, K2, CO, G5Â², QW | Simple |
| Dependency/topological sort | DT, GPT, K2, CO, G5Â², MM | Medium |
| File size ascending | CO | Simple |
| Centrality score (most-imported) | CO, GPT | Medium-Large |

### 5.5 Novel Proposal: Tests Before Source

ChatGPT 5.2 proposed a radical reordering unique among all models:

```
config â†’ public API source â†’ TESTS â†’ internal source â†’ docs
```

**Rationale**: "LLM reasoning improves when expectation is known *before* implementation." Tests encode invariants, usage intent, and hidden contracts â€” reading them first allows deductive (not inductive) code comprehension.

---

## 6. Consensus: Tier 2 Features

| Feature | Models Proposing | Total |
|---------|-----------------|-------|
| **Dependency graph / module map** | DT, GP, GR, QW, G5, G5Â², GPT, K2, CO | **9/10** |
| **Signature-only / skeleton mode** | DT, GP, QW, G5, G5Â², K2, CO, MM | **8/10** |
| **Git-aware context / change heatmap** | DT, GP, GR, G5, G5Â², K2, MM | **7/10** |
| **Semantic chunking (AST-aware)** | QW, G5, K2, CO, MM | **5/10** |
| **Structured output (XML/JSON)** | DT, G5, MM | **3/10** |
| **Smart diff (move/rename detection)** | GR, CO, MM | **3/10** |
| **Cross-reference annotations** | QW, GPT, CO | **3/10** |
| **Interactive query mode** | DT, MM | **2/10** |

**Top 3 for next implementation cycle**:
1. ðŸ¥‡ Dependency graph / module map (9/10 â€” near-universal consensus)
2. ðŸ¥ˆ Signature-only mode (8/10 â€” critical for token budget management)
3. ðŸ¥‰ Git-aware context (7/10 â€” recent changes as relevance signal)

---

## 7. Consensus: Output Format v2

### 7.1 Format Preference

| Format | Models | Argument |
|--------|--------|----------|
| Enhanced Markdown | GPT, K2, CO, G5Â² | Human-readable AND LLM-friendly |
| XML with CDATA | DT, MM | Prevents code block inception, machine-parseable |
| Markdown default + `--format` flag | K2, MM | Backward compatible |

### 7.2 Structural Consensus

Every model independently proposed a v2 format following this general structure:

```
1. Project metadata (name, version, hash, token count)
2. Architecture overview (natural language + dependency graph)
3. File manifest table (path, category, size, tokens, purpose)
4. Optional: Public API / signatures section
5. Full file contents (with per-file metadata headers)
6. Truncation notice if budget exceeded
```

### 7.3 Most Innovative Proposals

| Innovation | Model | Impact |
|-----------|-------|--------|
| Signatures-first progressive disclosure | Claude Opus | ~40% token reduction for large files |
| `<![CDATA[]]>` for code content | Gemini Deep Think | Eliminates markdown-in-markdown inception |
| Per-file `[category:N]` tags | Claude Opus | Machine-parseable relevance metadata |
| Commit heatmap (ðŸ”¥) | Kimi K2.5 | Visual frequency signal |
| Reliability column | GLM-5 run 2 | Inferred trust score per module |
| Centrality scores | Kimi K2.5 | Quantitative module importance |
| Tests-before-source | ChatGPT 5.2 | Deductive comprehension flow |

---

## 8. Methodology Analysis: Agentic vs One-Shot

### 8.1 Comparison

| Aspect | ðŸ¤– Agentic (Opus, MiniMax) | ðŸ§  One-Shot (8 others) |
|--------|---------------------------|------------------------|
| Bug verification | Can search/grep for exact lines | Must infer from context window |
| Line citations | Exact (tool-verified) | Approximate or absent |
| Missing context | Can request more files | Must work with what's given |
| False positives | Lower (can verify claims) | Higher (inferring from memory) |
| Cost per review | Higher (many API calls) | Lower (single inference) |
| Latency | Minutes (multi-step) | Seconds to minutes |

### 8.2 Conclusion

For code review of context-builder's pre-packaged context files, **one-shot reasoning was surprisingly competitive with agentic sessions**. The key differentiator was not *finding* bugs (Deep Think matched Opus in depth with 2 unique architectural bugs each) but *citing* them precisely (Opus could grep for exact line numbers).

This has implications for context-builder itself: **if the context file is well-structured with good relevance ordering, one-shot models can perform at near-agentic quality** â€” which validates the tool's core value proposition.

---

## 9. Model Personality Profiles

| Model | Method | Style | Strength | Weakness |
|-------|--------|-------|----------|----------|
| **Claude Opus 4.6** | ðŸ¤– | Surgical, evidence-based | Line-level citations, exact locations | Agentic overhead; verbose |
| **Gemini Deep Think** | ðŸ§  | Adversarial auditor | Deepest bugs in one shot (BTreeMap, DefaultHasher) | Slightly speculative on edge cases |
| **ChatGPT 5.2** | ðŸ§  | Systems thinker | Most original ideas (deductive ordering) | Brief on verification details |
| **Qwen-3-Max** | ðŸ§  | Technically precise | Thorough on new bugs, token math | Less creative on format proposals |
| **Kimi K2.5** | ðŸ§  | Pragmatic engineer | Balanced analysis, implementable suggestions | Less aggressive on bug hunting |
| **MiniMax Agent** | ðŸ¤– | Academic reviewer | Thorough, systematic structure | Conservative despite tool access |
| **GLM-5** (run 2) | ðŸ§  | Context-limited analyst | Unique binary cache bug | Missing core source files |
| **Gemini Pro** | ðŸ§  | Balanced reviewer | Good verification of known fixes | Fewer unique insights |
| **Grok 4.1** | ðŸ§  | Conservative reviewer | Safe, accurate | Fewest bugs, least novel proposals |
| **GLM-5** (run 1) | ðŸ§  | Truncation victim | Accidentally exposed lockfile starvation bug | Couldn't review actual code |

---

## 10. Immediate Action Items (Prioritized)

| Priority | Fix | Models | Effort |
|----------|-----|--------|--------|
| ðŸ”´ P0 | Implement `max_tokens` enforcement in parallel path | 4/10 | Medium |
| ðŸ”´ P0 | Replace mtime hash with content hash | 6/10 | Small-Medium |
| ðŸ”´ P0 | Replace `DefaultHasher` with stable hasher (blake3/xxhash) | 4/10 | Small |
| ðŸ”´ P0 | Fix auto-diff BTreeMap ordering (use relevance-sorted Vec) | 1/10 | Small |
| ðŸŸ¡ P1 | Elevate README/AGENTS.md to category 0 | 7/10 | Small |
| ðŸŸ¡ P1 | Elevate entry points (main.rs, lib.rs) within source | 9/10 | Small |
| ðŸŸ¡ P1 | Account for header/tree tokens in budget | 2/10 | Small |
| âœ… Done | Fix lockfile starvation (Cargo.lock â†’ category 4) | 10/10 | Done |
| âœ… Done | Fix test substring false positives (path boundaries) | 3/10 | Done |

---

## Appendix A: Raw Response Files

| Model | Response File |
|-------|--------------|
| Gemini 3 Deep Think | [`context_v2_resp-gemini-3-deepthink.md`](v2-responses/context_v2_resp-gemini-3-deepthink.md) |
| Gemini 3 Pro | [`context_v2_resp-gemini-3-pro.md`](v2-responses/context_v2_resp-gemini-pro.md) |
| Grok 4.1 | [`context_v2_resp-grok-4.1.md`](v2-responses/context_v2_resp-grok.md) |
| Qwen-3-Max | [`context_v2_resp-qwen-3-max.md`](v2-responses/context_v2_resp-qwen3-max.md) |
| GLM-5 (run 1) | [`context_v2_resp-glm5.md`](v2-responses/context_v2_resp-glm5.md) |
| GLM-5 (run 2) | [`context_v2_resp-glm5-run2.md`](v2-responses/context_v2_resp-glm5-run2.md) |
| ChatGPT 5.2 | [`context_v2_resp-chat-gpt-5.2.md`](v2-responses/context_v2_resp-chat-gpt-5.2.md) |
| Kimi K2.5 | [`context_v2_resp-kimi-k2.5.md`](v2-responses/context_v2_resp-kimi-k2.5.md) |
| Claude Opus 4.6 | [`context_v2_resp-claude-opus-4.6.md`](v2-responses/context_v2_resp-claude-opus-4.6.md) |
| MiniMax Agent 2.5 | [`context_v2_resp-minimax-agent.md`](v2-responses/context_v2_resp-minimax-agent.md) |

## Appendix B: Context File Used

- **Pre-fix context**: [`deepthink_context_v2.md`](context-files/deepthink_context_v2.md) (original, Cargo.lock at position 0)
- **Post-fix context**: [`deepthink_context_v2_fixed.md`](context-files/deepthink_context_v2_fixed.md) (lockfile fix applied, Cargo.lock at position last)
- **Prompt template**: [`deep_think_prompt_v2.md`](prompts/deepthink_prompt_v2.md)

